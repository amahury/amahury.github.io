---
title: "Review | The Algorithmic Origins of Life"
date: 2025-01-31 00:00:00 -0400
categories: [Opinion]
tags: [review, paper]
comments: true
toc: true 
math: true
pin: false
mermaid: false
description: For many years there has been a dispute over the computational nature of life at its origins. Moving beyond that confrontation, Sara Walker and Paul Davies offer us an information-first alternative. This happens to be one of my favorite papers, which is why I have enthusiastically written a review of it. 
alpez:
  name: Amahury J. L. Diaz
  twitter: amahury0
---
### Introduction
In [1865](https://gallica.bnf.fr/ark:/12148/bpt6k152107/f369.table) Rudolf [Clausius](https://en.wikipedia.org/wiki/Rudolf_Clausius). introduced the concept of entropy, derived from the Greek words “ἐν” (en) meaning “in” and “τροπή” (tropē) meaning “transformation”. Translated from German (“Verwandlung Inhalt”), it becomes “transformation content.” Around 1872, [Ludwig Boltzmann](https://es.wikipedia.org/wiki/Ludwig_Boltzmann) further defined entropy as a measure of the number of microscopic states of a system in thermodynamic equilibrium, formulating an elegant logarithmic relationship between entropy and probability. This groundbreaking expression inspired [Harry Nyquist](https://en.wikipedia.org/wiki/Harry_Nyquist) in [1924](https://ieeexplore.ieee.org/abstract/document/5060996) to propose a similar relationship that correlated the speed of intelligence transmission with the number of distinct voltage levels available per time step.

Similarly, in [1928](https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1928.tb01236.x), Ralph [Hartley](https://en.wikipedia.org/wiki/Ralph_Hartley) used an expression analogous to the one proposed by Boltzmann and Nyquist, this time relating the receiver's ability to distinguish one sequence of symbols from any other and the number of possible symbols. In this way, Hartley implicitly envisioned a link between entropy and information, leading to a long list of technological applications, including the statistical analysis carried out by Alan Turing in 1940 to decipher the [Enigma](https://en.wikipedia.org/wiki/Cryptanalysis_of_the_Enigma) code during the second world war. This insight paved the way for [Claude Shannon](https://en.wikipedia.org/wiki/Claude_Shannon) who, in [1948](https://ieeexplore.ieee.org/abstract/document/6773024), by means of an expression analogous to that used by [Gibbs](https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs) that generalizes Boltzmann's entropy, introduced the communication process as a statistical phenomenon, forging the foundations of [information theory](https://en.wikipedia.org/wiki/Information_theory).

Today, information permeates our world, influencing fields as diverse as telecommunications, the Internet of Things, large language models and, why not, life. As explained in _[The Algorithmic Origins of Life](https://doi.org/10.1098/rsif.2012.0869)_ by Walker and Davies, neither genetic-first nor metabolism-first approaches can completely describe the emergence of living organisms. Both viewpoints neglect the active (algorithmic or instructional) and distributed nature of biological information. In this way, _"the real challenge of life’s origin is thus to explain how instructional information control systems emerge naturally and spontaneously from mere molecular dynamics"_. Although published over a decade ago, this paper remains a cornerstone in the field, and since it is one of my favorites, today I bring you a review of it. 

### Traditional Approaches to the Origin of Life
The origin of life is one of science’s most profound mysteries. Traditional theories primarily fall into two paradigms: the “genetics-first” and “metabolism-first” hypotheses. The genetics-first model posits that early life relied on digital information stored in molecules such as [RNA](https://en.wikipedia.org/wiki/RNA), which served both as genetic material and enzymatic catalyst. This view aligns with the [RNA world](https://en.wikipedia.org/wiki/RNA_world) hypothesis, which considers RNA a precursor to [DNA](https://en.wikipedia.org/wiki/DNA)-based life. However, Walker and Davies point out critical limitations, including the immense chemical challenges of prebiotic RNA synthesis and the inability of single-molecule systems to separate information storage from processing.

Conversely, metabolism-first approaches suggest life began as analogue systems driven by [autocatalytic cycles](https://pmc.ncbi.nlm.nih.gov/articles/PMC7126077/). These systems encoded information through molecular composition rather than digital sequences. While chemically simpler and more [plausible](https://en.wikipedia.org/wiki/Autocatalytic_set) under prebiotic conditions, these models struggle with issues like reprogrammability, control, and long-term evolvability. Analogue systems lack the robustness and adaptability of modern life, which integrates analogue and digital information to achieve complexity and flexibility. Consequently, both paradigms fail to address the full spectrum of life’s complexity.

Walker and Davies argue that these models fall short because they neglect the active, algorithmic nature of [biological information](https://plato.stanford.edu/entries/information-biological/). Living systems do more than process information—they use it actively to drive dynamics, enabling feedback and evolvability. They emphasize that life’s origin required more than increased chemical complexity; it necessitated a reorganization of the system’s logical structure, allowing information to act as a [causal agent](https://link.springer.com/article/10.1007/s13752-024-00471-7). 

### An _Information-first_ Approach
At the heart of Walker and Davies’ argument is the notion that life’s defining feature is its informational architecture. Living systems exhibit [top-down causation](https://royalsocietypublishing.org/doi/10.1098/rsfs.2011.0062), where higher organizational levels influence lower levels. This stands in stark contrast to non-living systems, governed solely by [bottom-up causality](https://en.wikipedia.org/wiki/Epiphenomenon). The authors suggest that life’s emergence parallels a physical [phase transition](https://en.wikipedia.org/wiki/Phase_transition), marked by a shift in causal architecture. As mentioned earlier, Instead of focusing on chemical complexity alone, they propose examining how information becomes a causal agent capable of shaping its substrate.

Drawing on [Turing](https://en.wikipedia.org/wiki/Turing_machine) and [von Neumann](https://en.wikipedia.org/wiki/Von_Neumann_universal_constructor)’s work, the authors explore parallels between life and computational devices. Von Neumann’s concept of a universal constructor—a machine capable of self-replication based on encoded instructions—offers valuable insights. Modern organisms share this division of labor: [DNA](https://en.wikipedia.org/wiki/DNA) serves as the informational blueprint, [ribosomes](https://en.wikipedia.org/wiki/Ribosome) as construction machinery, and [cellular processes](https://en.wikipedia.org/wiki/Cell_(biology)#Cellular_processes) as supervisory units. However, life’s algorithmic nature is more distributed and context-dependent than von Neumann’s automata, requiring intricate interplay between localized and system-wide information.

A critical distinction made by Walker and Davies is between trivial and non-trivial [self-replicators](https://en.wikipedia.org/wiki/Self-replication). Trivial replicators, like crystals, rely on [passive replication](https://royalsocietypublishing.org/doi/10.1098/rstb.2006.1912). In contrast, non-trivial replicators actively process and adapt information. The transition from trivial to non-trivial replication represents a fundamental step in life’s emergence, enabling systems to manage complex, context-dependent information. The authors describe this transformation as an “algorithmic takeover,” where nucleic acids—as instructional molecules—control biomolecular synthesis and organization, fostering specialization and adaptability.

As mentioned above, central to the authors’ framework is the concept of top-down causation, wherein information manipulates the matter it is instantiated in, enabling a bidirectional flow of causality. Such a concept is very controversial even today, as many people argue that such a conception simply does not exist, as it is a mere _[façon de parler](https://arxiv.org/pdf/1207.4808)_. Although controversial, Walker and Davies argue that life originated with distributed information control, enabling context-dependent causation and feedback. Furthermore, they propose measurable parameters, like [integrated information](https://en.wikipedia.org/wiki/Integrated_information_theory), to quantify this transition.

### Conclusion
Walker and Davies present a paradigm shift in understanding life’s origins, focusing on information as a causal agent. They argue that life’s emergence is best understood as a transition in causal structure, where information gains control over matter. This perspective redefines the origin-of-life problem and provides a flexible framework for studying alternative life forms, whether chemical or non-organic. By prioritizing informational and causal aspects, the authors lay a foundation for new research avenues in astrobiology, biophysics, and complexity science.

Despite their compelling framework, significant questions remain unanswered. For instance, how does information control emerge ab initio in an RNA world, and how do primitive control mechanisms evolve after the algorithmic takeover? These challenges highlight the need for deeper exploration and integration of theoretical insights from past and present literature. How many “sleeping beauties” of knowledge await rediscovery? This is a call to delve into the vast existing literature rather than reinvent the wheel. Only by building on the shoulders of giants can we hope to unravel the phenomenon of life.

![Desktop View](/assets/img/fix/complexity-cat-newsletter.png){: .normal width="1200" height="630" }
